\input{header.tex}
% -----------------------------------------------------------------------------
\title{Solutions for exercise sheet 7}
\subtitle{Numerical Optimization: Convergence, general descent methods, CG}
% -----------------------------------------------------------------------------
\usepackage{algorithm} % algorithm floating env
\usepackage{algpseudocode}
% =============================================================================
\begin{document}
\maketitle

\paragraph{Exercise 7.1} % Nocedal 2.12
$x^* = 0$,
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|} = \left|\frac{k}{k+1}\right| < 1,
\]
and
\[
\lim_{k\to\infty} \frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|} = 1,
\]
so
\[
\forall r\in(0,1)\: \exists k_0: \frac{k}{k+1} > r \quad\forall k>k_0.
\]
This means that the sequence is \emph{not} Q-linearly convergent.


\paragraph{Exercise 7.2} % Nocedal 2.13
$x^* = 1$,
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|^2}
= \frac{(1/2)^{2^{k+1}}}{((1/2)^{2k})^2}
= \frac{(1/2)^{2^{k+1}}}{(1/2)^{2k+1}}
= 1 < \infty,
\]
so the sequence is Q-quadratically convergent.


\paragraph{Exercise 7.3} % Nocedal 2.15
For even $k$, we have
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|}
= \frac{x_k/k}{x_k}
= \frac{1}{k}
\to 0;
\]
and for odd $k$
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|}
= \frac{(1/4)^{2^k}}{x_{k-1}/k}
= k \frac{(1/4)^{2^k}}{(1/4)^{2^{k-1}}}
= k (1/4)^{2^{k-1}}
\to 0.
\]
Consequently,
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|} \to 0,
\]
i.e., the sequence converges Q-superlinearly.

On the other hand, for even $k$,
\[
\frac{\|x_{k+1}-x^*\|}{\|x_k-x^*\|^2}
= \frac{x_k/k}{x_k^2} = \frac{1}{k}4^{2^k} \to \infty,
\]
so the sequence is \emph{not} Q-quadratically convergent.

\paragraph{Exercise 7.4} % Nocedal 3.7
We have
\[
x_{k+1} = x_k - \alpha \nabla f_k
\]
such that
\[
(x_{k+1} - x^*) = (x_k-x^*) - \alpha \nabla f_k.
\]
From this, we get
\[
\begin{split}
\|x_{k+1} - x^*\|_A^2
&= (x_{k+1} - x^*)^\tp A (x_{k+1} - x^*)\\
&= ((x_{k} - x^*) - \alpha\nabla f_k)^\tp A ((x_k - x^*) - \alpha \nabla f_k)\\
&= \underbrace{(x_{k} - x^*) A (x_k - x^*)}_{=\|x_k-x^*\|_A^2} - 2\alpha\nabla f_k^\tp A(x_k-x^*) + \alpha^2\nabla f_k^\tp A \nabla f_k
\end{split}
\]
Knowing that $\nabla f_k=A(x_k - x^*)$ and $\alpha = \nabla
f(x_k)^\tp\nabla f_k/(\nabla f_k^\tp A\nabla f_k)$, it follows that
\[
\begin{split}
\|x_{k+1} - x^*\|_A^2
&= \|x_k - x^*\|_A^2  - 2\alpha \nabla f_k^\tp \nabla f_k + \alpha^2\nabla f_k^\tp A\nabla f_k\\
&= \|x_k - x^*\|_A^2
  - 2\frac{(\nabla f_k^\tp \nabla f_k)^2}{\nabla f_k^\tp A \nabla f_k}
  + \frac{(\nabla f_k^\tp \nabla f_k)^2}{\nabla f_k^\tp A \nabla f_k}\\
&= \|x_k - x^*\|_A^2
  - \frac{(\nabla f_k^\tp \nabla f_k)^2}{\nabla f_k^\tp A \nabla f_k}\\
&= \|x_k - x^*\|_A^2
\left(
1
- \frac{(\nabla f_k^\tp \nabla f_k)^2}{(\nabla f_k^\tp A \nabla f_k)\|x_k - x^*\|_A^2}
\right)\\
&= \|x_k - x^*\|_A^2
\left(
1
- \frac{(\nabla f_k^\tp \nabla f_k)^2}{(\nabla f_k^\tp A \nabla f_k)(\nabla f_k^\tp A^{-1} \nabla f_k)}.
\right)
\end{split}
\]

\paragraph{Exercise 7.5} % Nocedal 3.6
If $x_0-x^*$ is an eigenvector (with eigenvalue $\lambda$) of $A$, then
\[
\nabla f(x_0)
= A x_0 - b
= A x_0 - A x^* + Ax^* -b
= A(x_0 - x^*)
= \lambda (x_0-x^*).
\]
From this follows that
\begin{align*}
\nabla f(x_0)^\tp \nabla f(x_0)       &= \lambda^2 (x_0-x^*)^\tp (x_0-x^*),\\
\nabla f(x_0)^\tp A\nabla f(x_0)      &= \lambda^3 (x_0-x^*)^\tp (x_0-x^*),\\
\nabla f(x_0)^\tp A^{-1}\nabla f(x_0) &= \lambda^1 (x_0-x^*)^\tp (x_0-x^*).
\end{align*}
Inserting this in equation from exercise 7.4 gives
\[
  \|x_{1} - x^*\|_A^2
  = \left(1 - \frac{\lambda^4 ((x_0-x^*)^\tp(x_0-x^*))^2}{(\lambda^3 (x_0-x^*)^\tp(x_0-x^*)(\lambda (x_0-x^*)^\tp(x_0-x^*)}\right)\|x_{0} - x^*\|_A^2
=0,
\]
i.e., $x_1 = x^*$.


%\paragraph{Exercise 7.6}
%Let $A$ be a positive definite symmetric matrix. Prove the
%\emph{Kantorovich\footnote{Leonid Vitaliyevich Kantorovich (1912--1986),
%    Soviet mathematician and economist, known for his theory and development
%    of techniques for the optimal allocation of resources. Nobel Prize in
%    Economics in 1975.} inequality}, i.e., that for any vector $x$
%\[
%  \frac{(x^\tp x)^2}{(x^\tp A x)(x^\tp A^{-1}x)}
%  \ge \frac{4\lambda_n\lambda_1}{(\lambda_n + \lambda_1)^2},
%\]
%where $\lambda_n$ and $\lambda_1$ are the largest and smallest eigenvalues of
%$A$, respectively.


\end{document}
% =============================================================================
